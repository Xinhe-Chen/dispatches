{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "554c5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import os\n",
    "from filter_01_6400_years import TSA64K\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af020061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the clustering model\n",
    "def load_cluster_model(model_file):\n",
    "\n",
    "    '''\n",
    "    load the clustering model\n",
    "\n",
    "    Arguments:\n",
    "        model_file: the json file that stores the clustering model \n",
    "        ### future work: complete codes that can also read pkl file\n",
    "\n",
    "    Return:\n",
    "        clustering_model\n",
    "    '''\n",
    "\n",
    "    # model_file should be in the same folder\n",
    "    result_path = model_file\n",
    "    clustering_model = TimeSeriesKMeans.from_json(result_path)\n",
    "\n",
    "    return clustering_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9269b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ws(clustering_model, pred_csv, years = 6400):\n",
    "\n",
    "    '''\n",
    "    calculate the demand frequency ws for the given data\n",
    "\n",
    "    Arguments:\n",
    "        pred_csv: csv file that stores the data we are going to predict\n",
    "\n",
    "        years: int, how many simulation years are we going to predict, default 6400\n",
    "\n",
    "    Return:\n",
    "        ws: with shape of (years, number of clusters)\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Use functions in TSA64K to get train_data\n",
    "    metric = 'euclidean'\n",
    "    tsa_task = TSA64K(pred_csv, metric, years)\n",
    "    dispatch_array = tsa_task.read_data()\n",
    "    tsa_task.read_input_pmax()\n",
    "    train_data, data_index = tsa_task.transform_origin_data(dispatch_array)\n",
    "\n",
    "    pred_res = []\n",
    "    day_01_count = []\n",
    "\n",
    "    # pred_res: list of (years, 364), are labels predicted by the clustering_model\n",
    "    for i in range(years):\n",
    "        year_data = train_data[i*364:(i+1)*364]\n",
    "        day_0 = 0\n",
    "        day_1 = 0\n",
    "        del_index = []\n",
    "        for idx, day in enumerate(year_data):\n",
    "            if day.sum() == 0:\n",
    "                day_0 += 1\n",
    "                del_index.append(idx)\n",
    "            elif day.sum() == 24:\n",
    "                day_1 += 1\n",
    "                del_index.append(idx)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # count how many 0/1 capacity factor days in one year.\n",
    "        day_01_count.append(np.array([day_0,day_1]))\n",
    "\n",
    "        # just pred the days that are not 0/1.\n",
    "        new_year_data = np.delete(year_data, del_index, axis = 0)\n",
    "\n",
    "        # In some cases, the whole year is 0 capacity, add an empty array\n",
    "        if len(new_year_data) == 0:\n",
    "            pred_res.append(np.array([]))\n",
    "        else:\n",
    "            pred_res.append(clustering_model.predict(new_year_data))\n",
    "\n",
    "    day_01_count = np.array(day_01_count)\n",
    "\n",
    "    # record the number of clusters\n",
    "    num_clusters = clustering_model.n_clusters\n",
    "\n",
    "    # count the 0/1 capacity days\n",
    "    ws = []\n",
    "    for c, yr in enumerate(pred_res):\n",
    "        elements, count = np.unique(yr,return_counts=True)\n",
    "        res_dict = dict(zip(elements,count))\n",
    "        count_dict = {}\n",
    "        for j in range(num_clusters):\n",
    "            if j in res_dict.keys():\n",
    "                count_dict[j] = res_dict[j]/364\n",
    "            else:\n",
    "                count_dict[j] = 0\n",
    "\n",
    "        # the first element in w is frequency of 0 cf days\n",
    "        w = [day_01_count[c][0]/364]\n",
    "        for k in count_dict.items():\n",
    "            w.append(k[1])\n",
    "\n",
    "        # the last element in w is frequency of 0 cf days\n",
    "        w.append(day_01_count[c][1]/364)\n",
    "        ws.append(w)\n",
    "\n",
    "    # ws now np.array with size of (years,32)\n",
    "    ws = np.array(ws)\n",
    "\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2622b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_x(input_data_x, pred_csv, years = 6400):\n",
    "\n",
    "    '''\n",
    "    read the input x from the csv\n",
    "\n",
    "    Arguments:\n",
    "        input_data_x: csv file that stores the input data \n",
    "\n",
    "        pred_csv: csv file that stores the data we are going to predict\n",
    "\n",
    "        years: int, how many simulation years are we going to use, default 6400\n",
    "\n",
    "    Return:\n",
    "        x: with shape of (years, 8)\n",
    "\n",
    "    '''\n",
    "    metric = 'euclidean'\n",
    "    tsa_task = TSA64K(pred_csv, metric, years)\n",
    "    dispatch_array = tsa_task.read_data()\n",
    "    tsa_task.read_input_pmax()\n",
    "    train_data, data_index = tsa_task.transform_origin_data(dispatch_array)\n",
    "\n",
    "    df_input_data = pd.read_hdf(input_data_x)\n",
    "\n",
    "    # rows: data_index\n",
    "    # cols: from jordan's code\n",
    "    x = df_input_data.iloc[data_index,[1,2,3,4,5,6,7,9]].to_numpy()\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e1f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_file = 'prescient_generator_inputs.h5'\n",
    "pred_csv = 'Dispatch_shuffled_data_0.csv'\n",
    "x = read_input_x(inp_file, pred_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c0654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
